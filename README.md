# Project Wannabe

**Project Wannabe** は、小説執筆に特化した AI モデル **「wanabi 24B」** ([wanabi 24B モデルへのリンク (Hugging Face - 要更新)]) と、その能力を最大限に引き出すための専用デスクトップアプリケーション（フロントエンド）を統合したプロジェクトです。

## 🎯 目的とコンセプト

このアプリケーションは、Mistral Small 3 Base (24B) をベースに、「小説家になろう」のデータセット等を用いて独自にファインチューニングされた **「wanabi 24B」モデル** ([wanabi 24B モデルへのリンク (Hugging Face - 要更新)]) の持つ、**小説生成に関する特有の能力**を最大限に引き出すことを目的としています。

「wanabi 24B」は、特定の指示形式を用いることで小説のアイデア出し、設定に基づいた本文生成、そして文脈に沿った続きの生成に特化させたファインチューニングモデルです。Project Wannabe は、このモデルとの最適なGUIを提供することで、ユーザーの執筆プロセスを強力にサポートします。

主な機能は以下の通りです。

*   **💡 「wanabi 24B」特化のアイデア生成:**
    タイトル、キーワード、ジャンル、あらすじ、設定、プロットといった小説の構成要素を、「wanabi 24B」が得意とする形式で指示し、アイデアを生成させます。一部の情報から他の要素を補完させることも可能です。
*   **✍️ 高度な本文生成:**
    詳細な設定やプロットを「wanabi 24B」が理解しやすい形で渡し、モデルの能力を活かした整合性の高い小説本文を生成させます。
*   **🔄 最適化された継続執筆支援 (Generate Forever):**
    「wanabi 24B」による自然な続きの生成を、専用インターフェースで効率的に行います。ユーザーは繰り返し生成されるテキストの中から当たりな文章をピックアップし、小説を**「選択」**で作り上げます。

この **Project Wannabe** アプリケーションは、「wanabi 24B」モデルの**連続生成能力（無限生成）**を最大限に活用する専用フロントエンドとして機能します。ローカル環境で動作するため、**コストや外部サービスの検閲フィルターを気にすることなく**、自由な試行錯誤（AI ガチャ）が可能です。ユーザーが生成されたテキストの中から最適なものを**「選択」**していくことで、誰でも容易に小説を創り上げられるように支援し、文章創作の敷居を下げることを目指します。

**前提:** このアプリケーションを使用するには、別途 **[KoboldCpp](https://github.com/LostRuins/koboldcpp)** をローカル環境で起動し、**[「wanabi 24B」モデル]([wanabi 24B モデルへのリンク (Hugging Face - 要更新)])**（または互換性のある GGUF 形式のモデル）をロードしておく必要があります。

## 🚀 主な機能 (Features)

*   **KoboldCpp 連携:** ローカルで起動中の KoboldCpp APIと連携し、LLM によるテキスト生成を行います。接続ポートは設定可能です。
*   **モード切替:**
    *   **小説生成モード:** 入力された本文や詳細情報に基づいて、小説の続きや冒頭を生成します。
    *   **アイデア出しモード:** 入力された詳細情報に基づいて、タイトル、キーワード、ジャンル、あらすじ、設定、プロットなどのアイデアを生成します。（本文は参照されません。）
*   **詳細情報管理:** 小説の構成要素（タイトル、キーワード、ジャンル、あらすじ、設定、プロット）を専用のUIで管理し、プロンプト生成に利用します。**全てを埋める必要はありません。** 全てをAIに委ねることもあります。各セクションは折りたたみ可能です。
*   **テキスト生成:**
    *   **単発生成 (Ctrl+G):** 現在の入力に基づいて一度だけテキストを生成します。
    *   **無限生成 (Generate Forever / F5):** 停止するまで継続的にテキストを生成し続けます。生成回数やコストに縛られず、納得のいく表現が見つかるまで試行錯誤を重ねましょう。
*   **テキスト編集:** メインの本文編集エリア、LLM出力表示エリア、メモエリアの3つのテキストエリアを提供します。標準的な編集操作（元に戻す、やり直し、コピー、ペーストなど）が可能です。
*   **ファイル入出力:**
    *   **プロジェクト保存/読込:** 現在の本文、詳細情報、メモの内容を `.json` 形式のプロジェクトファイルとして保存・読み込みできます。
    *   **出力書き出し:** メインの本文エリアの内容を `.txt` ファイルとして書き出すことができます。書き出し時にタイトルを含めるか選択可能です。
*   **テキスト転記:**
    *   **出力 → 本文:** LLM出力エリアで選択したテキストを、本文エリアのカーソル位置に転記します。
    *   **出力 → メモ:** LLM出力エリアで選択したテキストを、メモエリアに追記します。
    *   **出力 → 詳細情報:** アイデア出しモードで生成された、特定の形式（`# 日本語名:\n値`）を持つテキストを選択し、対応する詳細情報欄（タイトル、キーワード、ジャンル、あらすじ、設定、プロット）に転記します。
        *   **例:** 出力エリアで以下のようなテキストブロックを選択し、
          ```
          # タイトル:
          異世界転生したら野良犬だった件

          # キーワード:
          異世界転生
          犬
          追放
          恋愛
          NTR

          # あらすじ:
          通り魔に刺されて死んだと思ったら、異世界で野良犬に転生していた。
          ```
        *   詳細情報タブの「タイトル」欄の横にある `← 転記` ボタンを押すと、「異世界転生したら野良犬だった件」がタイトル欄に転記されます。「キーワード」や「あらすじ」も同様に転記できます。
*   **表示設定:**
    *   **テーマ:** ライトテーマとダークテーマを切り替え可能です。
    *   **フォント:** アプリケーション全体で使用するフォントの種類とサイズを設定可能です。
*   **メモ機能:** 執筆中のアイデアや参照情報などを自由に書き留めておけるメモエリアを提供します。

## 使い方 (Usage)

1.  **前提:** KoboldCpp を起動し、「wanabi 24B」モデル（GGUF形式）をロードしておきます。
2.  **起動:** ターミナルで `python main.py` を実行してアプリケーションを起動します。
3.  **初期設定 (初回):**
    *   メニューバーの `設定` > `KoboldCpp 設定...` を開き、KoboldCpp がリッスンしているポート番号（デフォルト: 5001）を確認・設定します。
    *   メニューバーの `設定` > `生成パラメータ設定...` を開き、Max Length, Temperature などの生成パラメータやストップシーケンスを必要に応じて調整します。
4.  **モード選択:** ツールバーの「小説生成」または「アイデア出し」ボタンでモードを切り替えます。
5.  **詳細情報入力:** 右側の「詳細情報」タブで、タイトル、キーワード、あらすじ、設定、プロットなどを入力します。これらの情報はプロンプト生成に利用されます。
6.  **本文入力 (小説生成モード):** 左上の本文エリアに、生成のベースとなる小説本文を入力または編集します。
7.  **生成開始:**
    *   **単発生成:** メニューバーの `生成` > `単発生成 (Ctrl+G)` を選択するか、ショートカットキーを押します。
    *   **無限生成:** メニューバーの `生成` > `無限生成 開始/停止 (F5)` を選択するか、ショートカットキーを押します。生成が開始され、左下の出力エリアに結果がストリーミング表示されます。
8.  **生成停止 (無限生成中):** 再度 `F5` キーを押すか、メニューの `無限生成 開始/停止` を選択します。
9.  **テキスト転記:**
    *   出力エリアで生成されたテキストを選択し、`[ 選択部分を本文へ転記 ]` ボタンで本文エリアに挿入します。
    *   出力エリアで生成されたテキストを選択し、`[ 選択部分をメモへ転記 ]` ボタンでメモエリアに追記します。
    *   アイデア出しモードで生成された `# タイトル:` などのテキストを選択し、詳細情報タブの各項目の横にある `← 転記` ボタンで対応する欄に転記します。
10. **プロジェクト保存:** メニューバーの `ファイル` > `名前を付けて保存...` を選択し、現在の作業内容（本文、詳細情報、メモ）を `.json` ファイルに保存します。
11. **プロジェクト読込:** メニューバーの `ファイル` > `開く...` を選択し、以前保存した `.json` ファイルを読み込みます。
12. **出力書出:** メニューバーの `ファイル` > `出力内容を書き出し...` を選択し、現在の**本文エリアの内容**を `.txt` ファイルとして保存します。

より詳細な手順については、[Quick Start Guide](docs/Quick_Start_Guide.md) を参照してください。

## 設定 (Configuration)

アプリケーションの設定は、メニューバーの `設定` および `表示` から変更でき、プロジェクトルートにある `config.json` ファイルに保存されます。

*   **KoboldCpp Port:** (`設定` > `KoboldCpp 設定...`)
    *   KoboldCpp API が動作しているポート番号。
    *   デフォルト: `5001`
*   **生成パラメータ:** (`設定` > `生成パラメータ設定...`)
    *   `Max Length`: 生成するテキストの最大長。
    *   `Temperature`: 生成のランダム性。値が高いほど多様な出力になります。
    *   `Min P`: Min-P サンプリングの値。
    *   `Top P`: Top-P (Nucleus) サンプリングの値。
    *   `Repetition Penalty`: 繰り返しペナルティ。
    *   `ストップシーケンス`: 生成を停止する文字列のリスト（1行に1つ）。
*   **表示設定:**
    *   **テーマ:** (`表示` > `テーマ切り替え`) アプリケーションの見た目（ライト/ダーク）。デフォルト: `light`
    *   **フォント:** (`表示` > `フォント設定...`) アプリケーション全体で使用するフォントファミリーとサイズ。デフォルト: システムのデフォルトフォント
*   **設定ファイル:** `config.json` (プロジェクトルートディレクトリ)
    *   上記の設定値がこのファイルにJSON形式で保存されます。直接編集することも可能ですが、アプリケーションからの変更が推奨されます。

## インストールと実行 (Installation & Running)

### 前提条件

*   **Python:** 3.9 以上
*   **Git:** ソースコードから実行する場合に必要です。
*   **KoboldCpp:** ローカル環境で別途起動し、**[「wanabi 24B」モデル (GGUF形式)]([wanabi 24B モデルへのリンク (Hugging Face - 要更新)])** または互換性のあるモデルをロードしている必要があります。 ([KoboldCpp](https://github.com/LostRuins/koboldcpp))

### インストール手順

1.  **リポジトリのクローン:**
    ```bash
    git clone https://github.com/kawaii-justice/Project-Wannabe.git
    ```
2.  **ディレクトリ移動:**
    ```bash
    cd Project-Wannabe
    ```
3.  **仮想環境の作成と有効化:**
    *   Windows (cmd.exe):
        ```bash
        python -m venv venv
        venv\Scripts\activate
        ```
4.  **依存ライブラリのインストール:**
    ```bash
    pip install -r requirements.txt
    ```
    (`requirements.txt` には `PySide6`, `qasync`, `httpx` が含まれています。)

KoboldCpp のセットアップを含む、より詳細な手順については [Quick Start Guide](docs/Quick_Start_Guide.md) を参照してください。

### 実行方法

1.  仮想環境が有効化されていることを確認します。
2.  プロジェクトのルートディレクトリ (`Project-Wannabe`) で以下のコマンドを実行します。
    ```bash
    python main.py
    ```

## 今後の予定 (Roadmap)

現在提供されている「wanabi 24B」モデルは、コンセプト実証のためのアルファ版です。今後の開発ロードマップは以下の通りです。

*   **wanabi 24B v1 (学習中):**
    *   リリース目標: 約2週間以内
    *   内容: アルファ版からの改善・調整版。
*   **wanabi 24B v2 (データセット準備中):**
    *   リリース目標: 数ヶ月以内
    *   内容: Pre-training を行い、さらに拡張されたデータセットを用いた指示学習 (SFT) を実施予定。より高性能なモデルを目指します。

*(注意: 上記ロードマップは現時点での予定であり、変更される可能性があります。)*

## 免責事項 / Limitations

*   **利用上の注意:** 本ソフトウェアおよび「wanabi 24B」モデルは、研究および実験的な目的で提供されています。利用者は、適用される法律および規制を遵守する責任を負います。違法な目的や他者の権利を侵害する目的での使用は固く禁じます。
*   **生成内容に関する注意:**
    *   **偏り:** 使用しているデータセットの特性上、生成される内容が特定の要素や表現に偏る可能性があります。
    *   **不適切な内容:** データセットには多様なテキストが含まれるため、未成年者の閲覧に適さない、または不快感を与える可能性のある文章が生成されることがあります。
    *   **品質の限界:** データセットのサイズや性質上、生成される文章の多様性、一貫性、文脈への追従性には限界があります。
*   **自己責任:** 本ソフトウェアおよびモデルの使用によって生じたいかなる結果についても、開発者は一切の責任を負いません。全て自己責任においてご利用ください。

## 謝辞 (Acknowledgements)

Project Wannabe の開発にあたり、以下のプロジェクトやツールから多大な影響と助力を受けました。心より感謝申し上げます。

*   **EasyNovelAssistant:** アプリケーションのアイデアと設計の参考にさせていただきました。
    *   [https://github.com/Zuntan03/EasyNovelAssistant](https://github.com/Zuntan03/EasyNovelAssistant)
*   **LLaMA-Factory:** 「wanabi 24B」モデルのファインチューニングを可能にしてくれた素晴らしいフレームワークです。
    *   [https://github.com/hiyouga/LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory)
*   **Gemini 2.5 Pro:** アプリケーション開発における様々な課題解決やコード生成において、強力なサポートを提供してくれました。
